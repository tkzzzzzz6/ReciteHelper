import speech_recognition as sr
import tkinter as tk
from tkinter import scrolledtext, ttk, font, filedialog
import time
import jieba
import threading
from difflib import SequenceMatcher
import queue
import numpy as np
from aip import AipSpeech  # ç™¾åº¦è¯­éŸ³è¯†åˆ«API
from aip import AipNlp  # æ·»åŠ ç™¾åº¦NLPæ”¯æŒ
import config
import re
from ttkthemes import ThemedTk  # æ·»åŠ ä¸»é¢˜æ”¯æŒ
import os

class RecitationChecker:
    def __init__(self, root):
        self.root = root
        self.root.title("æ–‡è¨€æ–‡èƒŒè¯µåŠ©æ‰‹")
        self.root.geometry("1200x800")
        
        # è®¾ç½®ä¸»é¢˜å’Œæ ·å¼
        style = ttk.Style()
        style.configure("Title.TLabel", font=("Microsoft YaHei", 16, "bold"))
        style.configure("Text.TLabel", font=("Microsoft YaHei", 12))
        style.configure("Stats.TLabel", font=("Microsoft YaHei", 11))
        
        # é…ç½®ç™¾åº¦è¯­éŸ³è¯†åˆ«
        self.APP_ID = config.APP_ID
        self.API_KEY = config.API_KEY
        self.SECRET_KEY = config.SECRET_KEY
        self.client = AipSpeech(self.APP_ID, self.API_KEY, self.SECRET_KEY)
        
        # é…ç½®ç™¾åº¦NLPå®¢æˆ·ç«¯
        self.nlp_client = AipNlp(config.NLP_APP_ID, config.NLP_API_KEY, config.NLP_SECRET_KEY)
        
        self.setup_ui()
        self.setup_variables()
        
    def setup_ui(self):
        # ä¸»å®¹å™¨
        main_container = ttk.Frame(self.root, padding="10")
        main_container.pack(fill=tk.BOTH, expand=True)
        
        # æ ‡é¢˜
        title_frame = ttk.Frame(main_container)
        title_frame.pack(fill=tk.X, pady=(0, 10))
        ttk.Label(title_frame, text="æ–‡è¨€æ–‡èƒŒè¯µåŠ©æ‰‹", style="Title.TLabel").pack()
        
        # æ·»åŠ æ–‡æœ¬æ ‡é¢˜æ˜¾ç¤º
        self.text_title_label = ttk.Label(
            title_frame,
            text="å½“å‰æ–‡æœ¬ï¼šæœªé€‰æ‹©",
            style="Text.TLabel"
        )
        self.text_title_label.pack(pady=5)
        
        # åˆ›å»ºå·¦å³åˆ†æ 
        self.paned = ttk.PanedWindow(main_container, orient=tk.HORIZONTAL)
        self.paned.pack(fill=tk.BOTH, expand=True)
        
        # å·¦ä¾§é¢æ¿ - èƒŒè¯µæ–‡æœ¬
        left_frame = ttk.LabelFrame(self.paned, text="èƒŒè¯µå†…å®¹", padding="5")
        self.paned.add(left_frame, weight=1)
        
        # åŸæ–‡è¾“å…¥ï¼ˆéšè—ï¼‰
        self.original_text = scrolledtext.ScrolledText(
            left_frame, 
            height=15, 
            font=("Microsoft YaHei", 12),
            wrap=tk.WORD
        )
        self.original_text.pack(fill=tk.BOTH, expand=True)
        
        # æ¨¡ç³Šæ–‡æœ¬æ˜¾ç¤º
        self.blur_text = scrolledtext.ScrolledText(
            left_frame,
            height=15,
            font=("Microsoft YaHei", 12),
            wrap=tk.WORD,
            background="#F5F5F5"
        )
        self.blur_text.pack(fill=tk.BOTH, expand=True)
        self.original_text.pack_forget()
        
        # å³ä¾§é¢æ¿ - è¯†åˆ«ç»“æœ
        right_frame = ttk.LabelFrame(self.paned, text="è¯†åˆ«ç»“æœ", padding="5")
        self.paned.add(right_frame, weight=1)
        
        self.result_text = scrolledtext.ScrolledText(
            right_frame,
            height=15,
            font=("Microsoft YaHei", 12),
            wrap=tk.WORD
        )
        self.result_text.pack(fill=tk.BOTH, expand=True)
        
        # æ§åˆ¶é¢æ¿
        control_frame = ttk.Frame(main_container, padding="5")
        control_frame.pack(fill=tk.X, pady=10)
        
        # è¿›åº¦æ¡å’Œè®¡æ—¶å™¨
        progress_frame = ttk.Frame(control_frame)
        progress_frame.pack(side=tk.LEFT, fill=tk.X, expand=True)
        
        self.progress = ttk.Progressbar(
            progress_frame, 
            length=300, 
            mode='determinate',
            style="Accent.Horizontal.TProgressbar"
        )
        self.progress.pack(side=tk.LEFT, padx=(0, 10))
        
        self.timer_label = ttk.Label(
            progress_frame,
            text="10:00",
            style="Text.TLabel"
        )
        self.timer_label.pack(side=tk.LEFT)
        
        # æ§åˆ¶æŒ‰é’®
        button_frame = ttk.Frame(control_frame)
        button_frame.pack(side=tk.RIGHT)
        
        self.start_button = ttk.Button(
            button_frame,
            text="å¼€å§‹èƒŒè¯µ",
            command=self.start_recognition,
            style="Accent.TButton",
            width=15
        )
        self.start_button.pack(side=tk.LEFT, padx=5)
        
        self.stop_button = ttk.Button(
            button_frame,
            text="åœæ­¢èƒŒè¯µ",
            command=self.stop_recognition,
            state=tk.DISABLED,
            width=15
        )
        self.stop_button.pack(side=tk.LEFT, padx=5)
        
        # æ·»åŠ æ–‡æœ¬é€‰æ‹©æŒ‰é’®
        self.select_text_button = ttk.Button(
            button_frame,
            text="é€‰æ‹©æ–‡æœ¬",
            command=self.select_text,
            width=15
        )
        self.select_text_button.pack(side=tk.LEFT, padx=5)
        
        # çŠ¶æ€æ 
        status_frame = ttk.Frame(main_container, padding="5")
        status_frame.pack(fill=tk.X, pady=(0, 5))
        
        self.stats_label = ttk.Label(
            status_frame,
            text="å‡†å¤‡å°±ç»ª",
            style="Stats.TLabel"
        )
        self.stats_label.pack(side=tk.LEFT)
        
    def setup_variables(self):
        self.is_recording = False
        self.audio_queue = queue.Queue()
        self.text_queue = queue.Queue()
        self.recognized_text = ""
        self.remaining_time = 600
        self.recognizer = sr.Recognizer()
        # è°ƒæ•´è¯­éŸ³è¯†åˆ«å‚æ•°ï¼Œæé«˜çµæ•åº¦
        self.recognizer.energy_threshold = 1500  # é™ä½èƒ½é‡é˜ˆå€¼ï¼Œæé«˜çµæ•åº¦
        self.recognizer.dynamic_energy_threshold = True  # å¼€å¯åŠ¨æ€é˜ˆå€¼
        self.recognizer.pause_threshold = 0.5  # ç¼©çŸ­åœé¡¿åˆ¤æ–­æ—¶é—´
        self.recognizer.phrase_threshold = 0.3  # é™ä½çŸ­è¯­é˜ˆå€¼
        self.recognizer.non_speaking_duration = 0.3  # ç¼©çŸ­éè¯´è¯åˆ¤æ–­æ—¶é—´
        self.correct_chars = set()
        self.current_sentence_index = 0
        self.sentences = []
        self.accumulated_text = ""  # ç”¨äºç´¯ç§¯è¯†åˆ«æ–‡æœ¬
        self.last_recognition_time = 0  # ç”¨äºæ§åˆ¶è¯†åˆ«é¢‘ç‡
        
        # åˆå§‹åŒ–æ–‡æœ¬ç›¸å…³å˜é‡
        self.current_text_path = None
        self.texts_dir = os.path.join(os.path.dirname(__file__), 'texts')
        
        # ç¡®ä¿textsç›®å½•å­˜åœ¨
        if not os.path.exists(self.texts_dir):
            os.makedirs(self.texts_dir)
    
    def select_text(self):
        """é€‰æ‹©è¦èƒŒè¯µçš„æ–‡æœ¬æ–‡ä»¶"""
        file_path = filedialog.askopenfilename(
            initialdir=self.texts_dir,
            title="é€‰æ‹©è¦èƒŒè¯µçš„æ–‡æœ¬",
            filetypes=(("æ–‡æœ¬æ–‡ä»¶", "*.txt"), ("æ‰€æœ‰æ–‡ä»¶", "*.*"))
        )
        
        if file_path:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    text_content = f.read().strip()
                
                # æ›´æ–°æ–‡æœ¬æ˜¾ç¤º
                self.original_text.delete(1.0, tk.END)
                self.original_text.insert(tk.END, text_content)
                
                # æ›´æ–°æ ‡é¢˜æ˜¾ç¤º
                text_name = os.path.splitext(os.path.basename(file_path))[0]
                self.text_title_label.config(text=f"å½“å‰æ–‡æœ¬ï¼š{text_name}")
                
                # ä¿å­˜å½“å‰æ–‡æœ¬è·¯å¾„
                self.current_text_path = file_path
                
                # é‡ç½®è¯†åˆ«çŠ¶æ€
                self.current_sentence_index = 0
                self.accumulated_text = ""
                self.update_blur_text()
                
                # å¯ç”¨å¼€å§‹æŒ‰é’®
                self.start_button.config(state=tk.NORMAL)
                
            except Exception as e:
                tk.messagebox.showerror("é”™è¯¯", f"æ— æ³•åŠ è½½æ–‡æœ¬æ–‡ä»¶ï¼š{str(e)}")
    
    def start_recognition(self):
        # æ£€æŸ¥æ˜¯å¦å·²é€‰æ‹©æ–‡æœ¬
        if not self.current_text_path:
            tk.messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©è¦èƒŒè¯µçš„æ–‡æœ¬ï¼")
            return
            
        original = self.original_text.get(1.0, tk.END).strip()
        # åªæŒ‰å¥å·åˆ†å‰²æ–‡æœ¬ï¼Œä¿ç•™å¥å·
        self.sentences = []
        temp_sentences = original.split('ã€‚')
        for s in temp_sentences:
            if s.strip():  # ç¡®ä¿ä¸æ˜¯ç©ºå­—ç¬¦ä¸²
                self.sentences.append(s.strip() + 'ã€‚')
        
        # ç§»é™¤æœ€åä¸€ä¸ªå¥å­çš„å¥å·ï¼ˆå¦‚æœåŸæ–‡æ²¡æœ‰ä»¥å¥å·ç»“å°¾ï¼‰
        if not original.endswith('ã€‚'):
            self.sentences[-1] = self.sentences[-1][:-1]
        
        self.current_sentence_index = 0
        self.accumulated_text = ""
        self.last_recognition_time = 0
        
        self.is_recording = True
        self.remaining_time = 600
        self.progress['value'] = 0
        
        self.start_button.config(state=tk.DISABLED)
        self.stop_button.config(state=tk.NORMAL)
        self.result_text.delete(1.0, tk.END)
        
        self.correct_chars.clear()  # é‡ç½®æ­£ç¡®å­—ç¬¦è®°å½•
        self.update_blur_text()  # æ›´æ–°æ¨¡ç³Šæ˜¾ç¤º
        
        # å¯åŠ¨å¤šçº¿ç¨‹
        threading.Thread(target=self.audio_capture_thread, daemon=True).start()
        threading.Thread(target=self.recognition_thread, daemon=True).start()
        threading.Thread(target=self.update_ui_thread, daemon=True).start()
        threading.Thread(target=self.timer_thread, daemon=True).start()
    
    def audio_capture_thread(self):
        with sr.Microphone(sample_rate=16000) as source:
            # ç¼©çŸ­ç¯å¢ƒå™ªéŸ³è‡ªé€‚åº”æ—¶é—´
            self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
            
            while self.is_recording:
                try:
                    # è°ƒæ•´ç›‘å¬å‚æ•°
                    audio = self.recognizer.listen(
                        source,
                        timeout=1,  # ç¼©çŸ­è¶…æ—¶æ—¶é—´
                        phrase_time_limit=2,  # ç¼©çŸ­çŸ­è¯­æ—¶é—´é™åˆ¶
                    )
                    self.audio_queue.put(audio)
                except sr.WaitTimeoutError:
                    continue
    
    def get_semantic_similarity(self, text1, text2):
        """ä½¿ç”¨ç™¾åº¦NLPåˆ¤æ–­è¯­ä¹‰ç›¸ä¼¼åº¦"""
        try:
            result = self.nlp_client.simnet(text1, text2)
            if result.get('score'):
                return result['score']
            return 0
        except Exception as e:
            print(f"NLPé”™è¯¯: {str(e)}")
            return 0

    def recognition_thread(self):
        while self.is_recording:
            try:
                audio = self.audio_queue.get(timeout=1)
                current_time = time.time()
                
                if current_time - self.last_recognition_time < 0.3:
                    continue
                
                audio_data = audio.get_wav_data()
                result = self.client.asr(audio_data, 'wav', 16000, {
                    'dev_pid': 1537,
                    'enable_voice_detection': True,
                })
                
                if result['err_no'] == 0:
                    recognized_text = result['result'][0]
                    if len(recognized_text.strip()) > 2:
                        current_sentence = self.sentences[self.current_sentence_index]
                        
                        # ä½¿ç”¨ç™¾åº¦NLPè¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦åˆ¤æ–­
                        similarity = self.get_semantic_similarity(recognized_text, current_sentence)
                        
                        if similarity > 0.7:  # è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
                            # ç›¸ä¼¼åº¦é«˜ï¼Œä½¿ç”¨åŸå¥
                            self.accumulated_text = current_sentence
                        elif similarity > 0.5:
                            # éƒ¨åˆ†ç›¸ä¼¼ï¼Œä½¿ç”¨è¯†åˆ«æ–‡æœ¬ä½†æ ‡è®°ä¸ºéƒ¨åˆ†åŒ¹é…
                            self.accumulated_text = recognized_text
                            self.partial_match = True
                        else:
                            # ç›¸ä¼¼åº¦ä½ï¼Œä½¿ç”¨è¯†åˆ«æ–‡æœ¬
                            self.accumulated_text = recognized_text
                            self.partial_match = False
                        
                        self.text_queue.put(self.accumulated_text)
                        self.last_recognition_time = current_time
                        
            except queue.Empty:
                continue
            except Exception as e:
                print(f"è¯†åˆ«é”™è¯¯: {str(e)}")
    
    def update_ui_thread(self):
        while self.is_recording:
            try:
                text = self.text_queue.get(timeout=0.1)
                self.result_text.delete(1.0, tk.END)
                self.result_text.insert(tk.END, self.recognized_text)
                self.real_time_compare()
            except queue.Empty:
                continue
    
    def timer_thread(self):
        while self.is_recording and self.remaining_time > 0:
            minutes = self.remaining_time // 60
            seconds = self.remaining_time % 60
            self.timer_label.config(text=f"{minutes:02d}:{seconds:02d}")
            self.progress['value'] = ((600 - self.remaining_time) / 600) * 100
            time.sleep(1)
            self.remaining_time -= 1
            
        if self.remaining_time <= 0:
            self.stop_recognition()
    
    def update_blur_text(self):
        self.blur_text.delete(1.0, tk.END)
        
        for i, sentence in enumerate(self.sentences):
            if i < self.current_sentence_index:
                # å·²å®Œæˆçš„å¥å­æ˜¾ç¤ºä¸ºç»¿è‰²
                self.blur_text.insert(tk.END, sentence, 'completed')
            elif i == self.current_sentence_index:
                # å½“å‰å¥å­æ˜¾ç¤ºä¸ºåŠé€æ˜
                for char in sentence:
                    if char in ['ï¼Œ', 'ï¼š', '"', '"', 'ã€‚']:
                        self.blur_text.insert(tk.END, char, 'punctuation')
                    else:
                        self.blur_text.insert(tk.END, 'âˆ', 'current')
            else:
                # æœªå¼€å§‹çš„å¥å­æ˜¾ç¤ºä¸ºæµ…ç°è‰²æ–¹å—
                for char in sentence:
                    if char in ['ï¼Œ', 'ï¼š', '"', '"', 'ã€‚']:
                        self.blur_text.insert(tk.END, char, 'punctuation')
                    else:
                        self.blur_text.insert(tk.END, 'â–¡', 'future')
            
            # æ·»åŠ æ®µè½é—´è·
            if i < len(self.sentences) - 1:
                self.blur_text.insert(tk.END, "\n")
        
        # é…ç½®æ ‡ç­¾æ ·å¼
        self.blur_text.tag_config('completed', foreground='#2ECC71', font=("Microsoft YaHei", 12, "bold"))
        self.blur_text.tag_config('current', foreground='#3498DB', font=("Microsoft YaHei", 12))
        self.blur_text.tag_config('future', foreground='#BDC3C7', font=("Microsoft YaHei", 12))
        self.blur_text.tag_config('punctuation', foreground='#34495E', font=("Microsoft YaHei", 12))
    
    def real_time_compare(self):
        if self.current_sentence_index >= len(self.sentences):
            return
        
        current_sentence = self.sentences[self.current_sentence_index]
        recognized = self.accumulated_text.strip()
        
        if len(recognized) < 5:
            return
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = SequenceMatcher(None, current_sentence, recognized).ratio()
        
        # ä½¿ç”¨æ›´å®½æ¾çš„åˆ¤æ–­æ ‡å‡†ï¼Œè€ƒè™‘å‘éŸ³ç›¸ä¼¼æ€§
        char_match_ratio = sum(1 for c in current_sentence if c in recognized) / len(current_sentence)
        
        # å¦‚æœaccumulated_textå°±æ˜¯current_sentenceï¼Œè¯´æ˜NLPå·²ç»ç¡®è®¤å‘éŸ³ç›¸è¿‘
        is_nlp_matched = (recognized == current_sentence)
        
        if is_nlp_matched or similarity > 0.4 or char_match_ratio > 0.6:
            self.current_sentence_index += 1
            self.accumulated_text = ""
            self.update_blur_text()
            
            if self.current_sentence_index < len(self.sentences):
                self.result_text.delete(1.0, tk.END)
                self.result_text.insert(tk.END, "âœ“ å½“å‰å¥èƒŒè¯µæ­£ç¡®ï¼\n\n", 'success')
                self.result_text.insert(tk.END, "ä¸‹ä¸€å¥ï¼š\n", 'prompt')
                self.result_text.insert(tk.END, f"{self.sentences[self.current_sentence_index]}\n\n", 'current')
                self.result_text.insert(tk.END, "æ‚¨çš„æœ—è¯»ï¼š\n", 'prompt')
            else:
                self.result_text.delete(1.0, tk.END)
                self.result_text.insert(tk.END, "ğŸ‰ æ­å–œï¼å…¨æ–‡èƒŒè¯µå®Œæˆï¼", 'success')
                self.stop_recognition()
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            total_sentences = len(self.sentences)
            completed_sentences = self.current_sentence_index
            
            stats = f"æ€»å¥æ•°: {total_sentences} | å·²å®Œæˆ: {completed_sentences} | "
            stats += f"è¿›åº¦: {(completed_sentences/total_sentences*100):.1f}%"
            if similarity > 0.6:
                stats += f" | å‡†ç¡®ç‡: {(similarity*100):.1f}%"
            self.stats_label.config(text=stats)
        
        # æ›´æ–°è¯†åˆ«ç»“æœæ˜¾ç¤º
        self.result_text.delete(1.0, tk.END)
        if self.current_sentence_index < len(self.sentences):
            self.result_text.insert(tk.END, "å½“å‰å¥ï¼š\n", 'prompt')
            self.result_text.insert(tk.END, f"{self.sentences[self.current_sentence_index]}\n\n", 'current')
        self.result_text.insert(tk.END, "æ‚¨çš„æœ—è¯»ï¼š\n", 'prompt')
        self.result_text.insert(tk.END, recognized, 'recognized')
    
    def stop_recognition(self):
        self.is_recording = False
        self.start_button.config(state=tk.NORMAL)
        self.stop_button.config(state=tk.DISABLED)
        self.real_time_compare()

if __name__ == "__main__":
    root = ThemedTk(theme="arc")  # ä½¿ç”¨ç°ä»£ä¸»é¢˜
    app = RecitationChecker(root)
    
    root.mainloop()
